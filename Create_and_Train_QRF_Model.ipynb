{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating and Training Quantile Random Forest (QRF) Models\n",
    "\n",
    "Version 19 December 2022, Selina Kiefer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input: csv-files\n",
    "continuous timeseries of input data (e.g. statistics of meteorological predictor fields), continuous timeseries of ground truth temperature in csv-format\n",
    "### Output: pt-file and txt-file\n",
    "Quantile Random Forests models in pt-format, file with metadata of the models in txt-format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the paths' to the defined functions and configuration file and set its name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the defined functions.\n",
    "PATH_defined_functions = './Defined_Functions/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path and name of the configuration file.\n",
    "PATH_configurations = './Configuration_Files/'\n",
    "ifile_configurations = 'Configurations_QRF_Model.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the necessary python packages and functions\n",
    "Nothing needs to be changed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary python packages.\n",
    "import yaml\n",
    "import calendar\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from skranger.ensemble import RangerForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the needed functions.\n",
    "import sys\n",
    "sys.path.insert(1, PATH_defined_functions)\n",
    "from read_in_csv_data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the configuration file and the data specified in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the configuration file (nothing needs to be changed here).\n",
    "with open(PATH_configurations+ifile_configurations) as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the input data and remove any unnamed columns as well as the index column (nothing \n",
    "# needs to be changed here).\n",
    "df_input_data = read_in_csv_data(config['PATH_input_data'], config['ifile_input_data'])\n",
    "df_input_data = df_input_data.loc[:, ~df_input_data.columns.str.contains('^Unnamed')]\n",
    "df_input_data = df_input_data.drop(['index'], axis =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the name of the columns containing the time and the variables of the input data.\n",
    "time_column_name_input_data = df_input_data.columns[0]\n",
    "var_column_name_input_data = df_input_data.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that everything is selected correctly (nothing needs to be changed here).\n",
    "print('Predictors used for training the ML model: ')\n",
    "print(var_column_name_input_data)\n",
    "print('Name of the column containing the time: ')\n",
    "print(time_column_name_input_data)\n",
    "print('Dataframe containing the predictors: ')\n",
    "df_input_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the ground truth and remove any unnamed columns as well as the index column (nothing \n",
    "# needs to be changed here).\n",
    "df_ground_truth = read_in_csv_data(config['PATH_ground_truth'], config['ifile_ground_truth'])\n",
    "df_ground_truth = df_ground_truth.loc[:, ~df_ground_truth.columns.str.contains('^Unnamed')]\n",
    "df_ground_truth = df_ground_truth.drop(['index'], axis =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the name of the columns containing the time and the variables of the ground truth.\n",
    "time_column_name_ground_truth = df_ground_truth.columns[0]\n",
    "var_column_name_ground_truth = df_ground_truth.columns[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that everything is selected correctly (nothing needs to be changed here).\n",
    "print('Predictand used for training the ML model: ')\n",
    "print(var_column_name_ground_truth)\n",
    "print('Name of the column containing the time: ')\n",
    "print(time_column_name_ground_truth)\n",
    "print('Dataframe containing the predictand: ')\n",
    "df_ground_truth.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting the input features' names and the winters to be evaluated \n",
    "From here on, nothing needs to be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list with all the start years of the winters in the evaluation period is created.\n",
    "start_years_of_winter = np.arange(config['start_year_of_first_winter'], config['start_year_of_last_winter']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another list containing the names of the input features is created. \n",
    "df_input_features = df_input_data.drop([time_column_name_input_data], axis=1)\n",
    "input_features = df_input_features.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing the input data for a leave-one(-winter)-out cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When performing a leave-one-out cross-validation appraoch, the training data needs to be\n",
    "# different for every left-out winter of the validation period. For an easy removal of the\n",
    "# winter to be left out, the time column of the input and the ground truth data is converted\n",
    "# to a datetime-object and then set as the index. \n",
    "df_input_data[time_column_name_input_data] = pd.to_datetime(df_input_data[time_column_name_input_data])\n",
    "df_input_data = df_input_data.set_index(time_column_name_input_data)\n",
    "\n",
    "df_ground_truth[time_column_name_ground_truth] = pd.to_datetime(df_ground_truth[time_column_name_ground_truth])\n",
    "df_ground_truth = df_ground_truth.set_index(time_column_name_ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training of the QRF-models with a leave-one(-winter)-out cross validation\n",
    "For every of these winters, a separate QRF model is trained and then saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, the actual training takes place. To perform a leave-one-out cross-validation, the \n",
    "# respective winter has to be cut out of the training data timeseries (.loc[]). Then, the \n",
    "# variable columns of the splitted training data (the one without the respective winter) is\n",
    "# written into a pandas dataframe for both, the input data and the ground truth. Now, the \n",
    "# Quantile (quantile=true) Random Forest (RangerForestRegressor) is trained (fit()) and saved\n",
    "# (torch.save) for further use. This is done for every winter in the evaluation period \n",
    "# separately.\n",
    "for start_year in start_years_of_winter:        \n",
    "    month_before_start_winter = datetime(start_year, config['start_month_winter']-1, config['start_day_winter'])\n",
    "    end_winter = datetime(start_year+1, config['end_month_winter'], config['end_day_winter'])\n",
    " \n",
    "    df_X_train = df_input_data.loc[(df_input_data.index < month_before_start_winter) | (df_input_data.index > end_winter)]    \n",
    "    df_y_train = df_ground_truth.loc[(df_ground_truth.index < month_before_start_winter) | (df_ground_truth.index > end_winter)]    \n",
    "    df_X_train = df_X_train.reset_index()\n",
    "    df_y_train = df_y_train.reset_index()\n",
    "    \n",
    "    df_y_train = df_y_train.drop([time_column_name_ground_truth], axis=1)\n",
    "    df_X_train = df_X_train.drop([time_column_name_input_data], axis=1)\n",
    "    \n",
    "    y_train = np.array(df_y_train)\n",
    "    X_train = np.array(df_X_train)   \n",
    " \n",
    "    if config['obtain_additional_details_of_trees']:\n",
    "        quantile_regresssion_forest = RangerForestRegressor(n_estimators=1000, min_mode_size=5, quantiles=True, enable_tree_details=True)\n",
    "        quantile_regresssion_forest = quantile_regresssion_forest.fit(X_train, np.squeeze(y_train))\n",
    "        torch.save(quantile_regresssion_forest, config['PATH_model']+'QRF_'+config['ground_truth']+'_'+config['location_ground_truth']+'_input_'+config['input_data']+'_'+config['location_input']+'_lead_'+str(config['lead_time'])+'d_without_'+str(start_year)+'_'+str(start_year+1)+'_with_tree_details.pt')        \n",
    "        print('Model without Winter '+str(start_year)+'/'+str(start_year+1)+' Trained.')\n",
    "    else: \n",
    "        quantile_regresssion_forest = RangerForestRegressor(n_estimators=1000, min_mode_size=5, quantiles=True)\n",
    "        quantile_regresssion_forest = quantile_regresssion_forest.fit(X_train, np.squeeze(y_train))\n",
    "        torch.save(quantile_regresssion_forest, config['PATH_model']+'QRF_'+config['ground_truth']+'_'+config['location_ground_truth']+'_input_'+config['input_data']+'_'+config['location_input']+'_lead_'+str(config['lead_time'])+'d_without_'+str(start_year)+'_'+str(start_year+1)+'.pt')\n",
    "        print('Model without Winter '+str(start_year)+'/'+str(start_year+1)+' Trained.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creation of the metadata as specified in the configuration file for all trained QRF models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to combine every relevant information about the QRF model and the training process,\n",
    "# everything which cannot be inferred from the code is written in a list. This information\n",
    "# has to be given manually in the configuration file. \n",
    "additional_info_on_variables=['dataset_input : '+config['dataset_input_data'],\n",
    "                             'dataset_ground_truth: '+config['dataset_ground_truth'],\n",
    "                              'type_input_data: '+config['type_input_data'],\n",
    "                              'type_ground_truth: '+config['type_ground_truth'],\n",
    "                              'unit_of_ground_truth_and_prediction : '+config['unit_of_ground_truth_and_prediction'],\n",
    "                             'training_period: '+config['training_period'], \n",
    "                            'start_month_winter: '+str(config['start_month_winter']),\n",
    "                              'start_day_winter: '+str(config['start_day_winter']),\n",
    "                            'end_month_winter: '+str(config['end_month_winter']),\n",
    "                              'end_day_winter: '+str(config['end_day_winter']),\n",
    "                              'lead_time_in_days: '+str(config['lead_time']),\n",
    "                             'training_type: '+config['training_type']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the metadata and the model parameters for all trained QRF models in one combined txt-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the relevant information about the QRF model and its training is combined and saved to a\n",
    "# txt-file. This is done only once for the whole evaluation period since the model setup is the\n",
    "# same for every winter. \n",
    "metadata_model = additional_info_on_variables\n",
    "qrf_hyperparameters = quantile_regresssion_forest.get_params()\n",
    "winter_left_out = 'validation_period_winters_left_out_one_at_a_time_: '+str(config['start_year_of_first_winter'])+'_'+str(config['start_year_of_last_winter']+1)\n",
    "metadata_model.append(winter_left_out)\n",
    "metadata_model.append('QRF_hyperparameters: '+str(qrf_hyperparameters))\n",
    "if config['obtain_additional_details_of_trees']:\n",
    "    file = open(config['PATH_model']+'QRF_'+config['ground_truth']+'_'+config['location_ground_truth']+'_input_'+config['input_data']+'_'+config['location_input']+'_lead_'+str(config['lead_time'])+'d_validation_'+str(config['start_year_of_first_winter'])+'_'+str(config['start_year_of_last_winter']+1)+'_with_tree_details.txt', 'w') \n",
    "else: \n",
    "    file = open(config['PATH_model']+'QRF_'+config['ground_truth']+'_'+config['location_ground_truth']+'_input_'+config['input_data']+'_'+config['location_input']+'_lead_'+str(config['lead_time'])+'d_validation_'+str(config['start_year_of_first_winter'])+'_'+str(config['start_year_of_last_winter']+1)+'.txt', 'w') \n",
    "file.write('\\n'.join(metadata_model))\n",
    "file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End of Program"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
