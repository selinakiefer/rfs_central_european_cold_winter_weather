{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the Ground Truth and the Predictions of the Climatological Ensemble and a QRF Model\n",
    "Version 21 December, Selina Kiefer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input: csv-files\n",
    "ensemble of continuous timeseries of ground truth temperature for a winter (e.g. climatological ensemble) in csv-format, predictions of a representative Quantile Random Forest model as continuous timeseries of temperature in csv-format, continuous timeseries of ground truth temperature in csv-format\n",
    "### Output: png-files\n",
    "winterwise plots of predicted and ground truth continuous temperature timeseries in png-format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the paths' to the defined functions, the style sheet for plotting and tthe configuration file and set its name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the defined functions.\n",
    "PATH_defined_functions = './Defined_Functions/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path and name of the style file which should be used for plotting.\n",
    "style_file_for_plotting = './Style_File_Matplotlib.mplstyle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path and name of the configuration file.\n",
    "PATH_configurations = './Configuration_Files/'\n",
    "ifile_configurations = 'Configurations_Visualization_Continuous_Prediction_Ensembles.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the necessary python packages and functions\n",
    "Nothing needs to be changed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary python packages.\n",
    "import yaml\n",
    "import numpy as np\n",
    "import calendar\n",
    "from datetime import datetime, timedelta\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the necessary defined functions.\n",
    "import sys\n",
    "sys.path.insert(1, PATH_defined_functions)\n",
    "from read_in_csv_data import *\n",
    "from truncate_data_by_date import*\n",
    "from create_auxiliary_date import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the style sheet for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the style sheet to be used by matplotlib for plotting. This will update the plotting\n",
    "# parameters to e.g. have the right font, font size and figure size. The latter is adjusted to\n",
    "# the textwidth of the LaTeX-document in order to avoid re-scaling the plot and changing \n",
    "# thereby the font size again.\n",
    "plt.style.use(style_file_for_plotting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the configuration file and the data specified in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the configuration file (nothing needs to be changed here).\n",
    "with open(PATH_configurations+ifile_configurations) as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read in the ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the continuous ground truth and remove any unnamed columns as well as the index \n",
    "# column (nothing needs to be changed here).\n",
    "df_ground_truth = read_in_csv_data(config['PATH_ground_truth'], config['ifile_ground_truth'])\n",
    "df_ground_truth = df_ground_truth.loc[:, ~df_ground_truth.columns.str.contains('^Unnamed')]\n",
    "df_ground_truth = df_ground_truth.drop(['index'], axis =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the name of the columns containing the time and the variables of the ground truth.\n",
    "time_column_name_ground_truth = df_ground_truth.columns[0]\n",
    "var_column_name_ground_truth = df_ground_truth.columns[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that everything is selected correctly (nothing needs to be changed here).\n",
    "print('Continuous ground truth: ')\n",
    "print(var_column_name_ground_truth)\n",
    "print('Name of the column containing the time: ')\n",
    "print(time_column_name_ground_truth)\n",
    "print('Dataframe containing the ground truth: ')\n",
    "df_ground_truth.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read in the climatological ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the continuous predictions of the climatological ensemble and remove any unnamed \n",
    "# columns as well as the index column (nothing needs to be changed here).\n",
    "df_climatological_ensemble = read_in_csv_data(config['PATH_climatological_ensemble'], config['ifile_climatological_ensemble'])\n",
    "df_climatological_ensemble = df_climatological_ensemble.loc[:, ~df_climatological_ensemble.columns.str.contains('^Unnamed')]\n",
    "df_climatological_ensemble = df_climatological_ensemble.drop(['index'], axis =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the name of the columns containing the time and the variables of the continuous \n",
    "# predictions of the climatological ensemble. \n",
    "time_column_name_climatological_ensemble = df_climatological_ensemble.columns[0]\n",
    "var_column_name_climatological_ensemble = df_climatological_ensemble.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that everything is selected correctly (nothing needs to be changed here).\n",
    "print('Names of the member of the climatological ensemble: ')\n",
    "print(var_column_name_climatological_ensemble)\n",
    "print('Name of the column containing the time: ')\n",
    "print(time_column_name_climatological_ensemble)\n",
    "print('Dataframe containing the climatological ensemble: ')\n",
    "df_climatological_ensemble.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read in the QRF predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the predictions of the QRF model and remove any unnamed columns as well as the index\n",
    "# column (nothing needs to be changed here).\n",
    "df_predictions_qrf = read_in_csv_data(config['PATH_predictions_qrf'], config['ifile_predictions_qrf'])\n",
    "df_predictions_qrf = df_predictions_qrf.loc[:, ~df_predictions_qrf.columns.str.contains('^Unnamed')]\n",
    "df_predictions_qrf = df_predictions_qrf.drop(['index'], axis =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the name of the columns containing the time and the variables of the predictions of the\n",
    "# QRF model.\n",
    "time_column_name_predictions_qrf = df_predictions_qrf.columns[0]\n",
    "var_column_name_predictions_qrf = df_predictions_qrf.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that everything is selected correctly (nothing needs to be changed here).\n",
    "print('Names of predictions done by the QRF model: ')\n",
    "print(var_column_name_predictions_qrf)\n",
    "print('Name of the column containing the time: ')\n",
    "print(time_column_name_predictions_qrf)\n",
    "print('Dataframe containing the predictions of the QRF model: ')\n",
    "df_predictions_qrf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the continuous ground truth, the climatological ensemble and the predictions of the QRF model for plotting\n",
    "From here on, nothing needs to be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list with all the start years of the winters in the evaluation period is created. \n",
    "start_years_of_winter = np.arange(config['start_year_of_first_winter'], config['start_year_of_last_winter']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, two different dataframes are created with the threshold for the cold wave \n",
    "# definition. One for regular years and one for leap years. Therefore, the index of the original\n",
    "# dataframe is set to the time and the index of the 29 February is determined. Then, a new \n",
    "# dataframe without the 29 February is created for regular years. The original dataframe is used\n",
    "# for leap years.\n",
    "df_climatological_ensemble[time_column_name_climatological_ensemble]=pd.to_datetime(df_climatological_ensemble[time_column_name_climatological_ensemble])\n",
    "df_climatological_ensemble = df_climatological_ensemble.set_index(time_column_name_climatological_ensemble)\n",
    "index_of_february_29 = df_climatological_ensemble[((df_climatological_ensemble.index.month == 2) & (df_climatological_ensemble.index.day == 29))].index\n",
    "df_climatological_ensemble_without_29_feb = df_climatological_ensemble.drop(index_of_february_29)\n",
    "df_climatological_ensemble = df_climatological_ensemble.reset_index()\n",
    "df_climatological_ensemble_without_29_feb = df_climatological_ensemble_without_29_feb.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a next step, the predictions of each year are extracted and saved to a list. The same is\n",
    "# done for the ground truth and the QRF predictions. The respective forecast dates of each year \n",
    "# are also saved to a list. This is done for each of the winters separately. \n",
    "climatological_ensemble = []\n",
    "predictions_qrf = []\n",
    "ground_truth = []\n",
    "forecast_dates = []\n",
    "\n",
    "for start_year_of_winter in start_years_of_winter:\n",
    "    \n",
    "    start_winter = datetime(start_year_of_winter, config['start_month_winter'], config['start_day_winter'])\n",
    "    end_winter = datetime(start_year_of_winter+1, config['end_month_winter'], config['end_day_winter'])\n",
    "\n",
    "    df_ground_truth_respective_winter = truncate_data_by_date(df_ground_truth, time_column_name_ground_truth, start_winter.strftime('%Y_%m_%d'), end_winter.strftime('%Y_%m_%d')) \n",
    "   \n",
    "    df_predictions_qrf_respective_winter = truncate_data_by_date(df_predictions_qrf, time_column_name_predictions_qrf, start_winter.strftime('%Y_%m_%d'), end_winter.strftime('%Y_%m_%d')) \n",
    "\n",
    "    if calendar.isleap(start_year_of_winter+1):\n",
    "        df_predictions_respective_winter = df_climatological_ensemble  \n",
    "    else:\n",
    "        df_predictions_respective_winter = df_climatological_ensemble_without_29_feb\n",
    "    \n",
    "    predictions_respective_winter = df_predictions_respective_winter.drop([time_column_name_climatological_ensemble], axis=1)\n",
    "    predictions_respective_winter = np.array(np.squeeze(predictions_respective_winter))\n",
    " \n",
    "    climatological_ensemble.append(predictions_respective_winter)\n",
    "    predictions_qrf.append(df_predictions_qrf_respective_winter[var_column_name_predictions_qrf])\n",
    "    \n",
    "    ground_truth.append(df_ground_truth_respective_winter[var_column_name_ground_truth])\n",
    "    forecast_dates.append(pd.to_datetime(df_ground_truth_respective_winter[time_column_name_ground_truth]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing the predictions of the climatological ensemble and the QRF model for separate winters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For illustration purposes, the median and two in the configuration file defined percentiles of\n",
    "# the predictions are plotted together with the ground truth. This gives a first impression\n",
    "# about the models' forecast skill.\n",
    "for k in range(len(start_years_of_winter)):\n",
    "    fig,ax = plt.subplots()\n",
    "    ax.fill_between(x=forecast_dates[k], y1=np.nanpercentile(climatological_ensemble[k], config['upper_quantile']*100, axis=1), y2=np.nanpercentile(climatological_ensemble[k], config['lower_quantile']*100, axis=1), color='r', alpha=0.25, label='Climatological Ensemble')\n",
    "    ax.fill_between(x=forecast_dates[k], y1=np.nanpercentile(predictions_qrf[k], config['upper_quantile']*100, axis=1), y2=np.nanpercentile(predictions_qrf[k], config['lower_quantile']*100, axis=1), color='b', hatch='.', alpha=0.2, label=config['qrf_model_name']+', '+str(config['lead_time'])+'d lead')  \n",
    "    ax.plot(forecast_dates[k], np.array(np.squeeze(ground_truth[k])), color='k', linestyle='--', label='Ground Truth')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylim(260, 290) \n",
    "    #plt.legend(bbox_to_anchor=(0, -0.45), loc='upper left')   # plot as standalone legend for paper\n",
    "    plt.ylabel(var_column_name_ground_truth+' in '+config['unit_continuous_ground_truth'])\n",
    "    plt.savefig(config['PATH_plots']+config['qrf_model_name']+'_predictions_'+config['continuous_ground_truth']+'_lead_'+str(config['lead_time'])+'d_'+str(start_years_of_winter[k])+'_'+str(start_years_of_winter[k]+1)+'.png', bbox_inches='tight')\n",
    "    #plt.show() # not used since the size of the jupyter notebook is really big\n",
    "    plt.close() # only used since the size of the jupyter notebook is really big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a standalone legend for the plot visualizing the climatological ensemble, the QRF\n",
    "# predictions and the ground truth.\n",
    "red_filling = mpatches.Patch(color='r', alpha=0.25, label='Climatological Ensemble')\n",
    "blue_dotted_filling = mpatches.Patch(color='b', hatch='.', alpha=0.2, label=config['qrf_model_name']+', '+str(config['lead_time'])+'d lead')\n",
    "black_dashed_line = plt.Line2D([], [], color='k', linestyle='--', label='Ground Truth Temperature (E-OBS)')\n",
    "plt.legend(handles=[red_filling, black_dashed_line, blue_dotted_filling], ncol=2)\n",
    "plt.axis(False)\n",
    "plt.savefig(config['PATH_plots']+'Standalone_legend_for_visualization_continuous_predictions.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End of Program"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
