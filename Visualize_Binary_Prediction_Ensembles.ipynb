{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the Ground Truth and the Predictions of the Climatological Ensemble and a RFC Model\n",
    "Version 21 December, Selina Kiefer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input: csv-files\n",
    "binary timeseries of cold wave days in the climatological ensemble in csv-format, predictions of a representative Random Forest Classifier models as binary timeseries of cold wave days in csv-format, binary timeseries of cold wave days in csv-format\n",
    "### Output: png-files\n",
    "winterwise plots of predicted and ground truth binary cold wave day timeseries in png-format  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the paths' to the defined functions, the style sheet for plotting and tthe configuration file and set its name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the defined functions.\n",
    "PATH_defined_functions = './Defined_Functions/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path and name of the style file which should be used for plotting.\n",
    "style_file_for_plotting = './Style_File_Matplotlib.mplstyle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path and name of the configuration file.\n",
    "PATH_configurations = './Configuration_Files/'\n",
    "ifile_configurations = 'Configurations_Visualization_Binary_Prediction_Ensembles.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the necessary python packages and functions\n",
    "Nothing needs to be changed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary python packages.\n",
    "import yaml\n",
    "import numpy as np\n",
    "import calendar\n",
    "from datetime import datetime, timedelta\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the necessary defined functions.\n",
    "import sys\n",
    "sys.path.insert(1, PATH_defined_functions)\n",
    "from read_in_csv_data import *\n",
    "from truncate_data_by_date import*\n",
    "from create_auxiliary_date import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the style sheet for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the style sheet to be used by matplotlib for plotting. This will update the plotting\n",
    "# parameters to e.g. have the right font, font size and figure size. The latter is adjusted to\n",
    "# the textwidth of the LaTeX-document in order to avoid re-scaling the plot and changing \n",
    "# thereby the font size again.\n",
    "plt.style.use(style_file_for_plotting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the configuration file and the data specified in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the configuration file (nothing needs to be changed here).\n",
    "with open(PATH_configurations+ifile_configurations) as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read in the ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the binary ground truth and remove any unnamed columns as well as the index column\n",
    "# (nothing needs to be changed here).\n",
    "df_cold_waves = read_in_csv_data(config['PATH_ground_truth'], config['ifile_ground_truth_cold_waves'])\n",
    "df_cold_waves = df_cold_waves.loc[:, ~df_cold_waves.columns.str.contains('^Unnamed')]\n",
    "df_cold_waves = df_cold_waves.drop(['index'], axis =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the name of the columns containing the time and the variables of the ground truth.\n",
    "time_column_name_cold_waves = df_cold_waves.columns[0]\n",
    "var_column_name_cold_waves = df_cold_waves.columns[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that everything is selected correctly (nothing needs to be changed here).\n",
    "print('Binary ground truth: ')\n",
    "print(var_column_name_cold_waves)\n",
    "print('Name of the column containing the time: ')\n",
    "print(time_column_name_cold_waves)\n",
    "print('Dataframe containing the ground truth: ')\n",
    "df_cold_waves.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read in the climatological ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the cold wave predictions of the climatological ensemble and remove any unnamed\n",
    "# columns as well as the index column (nothing needs to be changed here).\n",
    "df_climatological_ensemble_cold_waves = read_in_csv_data(config['PATH_climatological_ensemble'], config['ifile_climatological_ensemble_cold_waves'])\n",
    "df_climatological_ensemble_cold_waves = df_climatological_ensemble_cold_waves.loc[:, ~df_climatological_ensemble_cold_waves.columns.str.contains('^Unnamed')]\n",
    "df_climatological_ensemble_cold_waves = df_climatological_ensemble_cold_waves.drop(['index'], axis =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the name of the columns containing the time and the variables of the cold wave predictions\n",
    "# of the climatological ensemble.\n",
    "time_column_name_climatological_ensemble_cold_waves = df_climatological_ensemble_cold_waves.columns[0]\n",
    "var_column_name_climatological_ensemble_cold_waves = df_climatological_ensemble_cold_waves.columns[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that everything is selected correctly (nothing needs to be changed here).\n",
    "print('Names of cold wave predictions of the climatological ensemble: ')\n",
    "print(var_column_name_climatological_ensemble_cold_waves)\n",
    "print('Name of the column containing the time: ')\n",
    "print(time_column_name_climatological_ensemble_cold_waves)\n",
    "print('Dataframe containing the cold wave predictions of the climatological ensemble: ')\n",
    "df_climatological_ensemble_cold_waves.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read in the RFC predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the predictions of the RFC model and remove any unnamed columns as well as the index\n",
    "# column (nothing needs to be changed here).\n",
    "df_predictions_rfc = read_in_csv_data(config['PATH_predictions_rfc'], config['ifile_predictions_rfc'])\n",
    "df_predictions_rfc = df_predictions_rfc.loc[:, ~df_predictions_rfc.columns.str.contains('^Unnamed')]\n",
    "df_predictions_rfc = df_predictions_rfc.drop(['index'], axis =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the name of the columns containing the time and the variables of the predictions of the\n",
    "# RFC model.\n",
    "time_column_name_predictions_rfc = df_predictions_rfc.columns[0]\n",
    "var_column_name_predictions_rfc = df_predictions_rfc.columns[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that everything is selected correctly (nothing needs to be changed here).\n",
    "print('Names of predictions done by the RFC model: ')\n",
    "print(var_column_name_predictions_rfc)\n",
    "print('Name of the column containing the time: ')\n",
    "print(time_column_name_predictions_rfc)\n",
    "print('Dataframe containing the predictions of the RFC model: ')\n",
    "df_predictions_rfc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the binary ground truth, the cold wave predictions of the climatological ensemble and the predictions of the RFC model for plotting\n",
    "From here on, nothing needs to be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list with all the start years of the winters in the validation period is created. \n",
    "start_years_of_winter = np.arange(config['start_year_of_first_winter'], config['start_year_of_last_winter']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At first, two different dataframes are created with the threshold for the cold wave \n",
    "# definition. One for regular years and one for leap years. Therefore, the index of the original\n",
    "# dataframe is set to the time and the index of the 29 February is determined. Then, a new \n",
    "# dataframe without the 29 February is created for regular years. The original dataframe is used\n",
    "# for leap years.\n",
    "df_climatological_ensemble_cold_waves[time_column_name_climatological_ensemble_cold_waves]=pd.to_datetime(df_climatological_ensemble_cold_waves[time_column_name_climatological_ensemble_cold_waves])\n",
    "df_climatological_ensemble_cold_waves = df_climatological_ensemble_cold_waves.set_index(time_column_name_climatological_ensemble_cold_waves)\n",
    "index_of_february_29 = df_climatological_ensemble_cold_waves[((df_climatological_ensemble_cold_waves.index.month == 2) & (df_climatological_ensemble_cold_waves.index.day == 29))].index\n",
    "df_climatological_ensemble_cold_waves_without_29_feb = df_climatological_ensemble_cold_waves.drop(index_of_february_29)\n",
    "df_climatological_ensemble_cold_waves = df_climatological_ensemble_cold_waves.reset_index()\n",
    "df_climatological_ensemble_cold_waves_without_29_feb = df_climatological_ensemble_cold_waves_without_29_feb.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a next step, the predictions of each year are extracted and saved to a list. The same is\n",
    "# done for the ground truth. The respective forecast dates of each year are also saved to a \n",
    "# list. This is done for each of the winters separately. \n",
    "climatological_ensemble_cold_waves = []\n",
    "predictions_rfc = []\n",
    "cold_waves = []\n",
    "forecast_dates = []\n",
    "\n",
    "for start_year_of_winter in start_years_of_winter:\n",
    "    \n",
    "    start_winter = datetime(start_year_of_winter, config['start_month_winter'], config['start_day_winter'])\n",
    "    end_winter = datetime(start_year_of_winter+1, config['end_month_winter'], config['end_day_winter'])\n",
    "\n",
    "    df_cold_waves_respective_winter = truncate_data_by_date(df_cold_waves, time_column_name_cold_waves, start_winter.strftime('%Y_%m_%d'), end_winter.strftime('%Y_%m_%d')) \n",
    "   \n",
    "    df_predictions_rfc_respective_winter = truncate_data_by_date(df_predictions_rfc, time_column_name_predictions_rfc, start_winter.strftime('%Y_%m_%d'), end_winter.strftime('%Y_%m_%d')) \n",
    "\n",
    "    if calendar.isleap(start_year_of_winter+1):\n",
    "        df_predictions_respective_winter = df_climatological_ensemble_cold_waves\n",
    "    else:\n",
    "        df_predictions_respective_winter = df_climatological_ensemble_cold_waves_without_29_feb\n",
    "    \n",
    "    predictions_respective_winter = df_predictions_respective_winter[var_column_name_climatological_ensemble_cold_waves]\n",
    "    predictions_respective_winter = np.array(np.squeeze(predictions_respective_winter))\n",
    " \n",
    "    climatological_ensemble_cold_waves.append(predictions_respective_winter)\n",
    "    predictions_rfc.append(df_predictions_rfc_respective_winter[var_column_name_predictions_rfc])\n",
    "    \n",
    "    cold_waves.append(df_cold_waves_respective_winter[var_column_name_cold_waves])\n",
    "    forecast_dates.append(pd.to_datetime(df_cold_waves_respective_winter[time_column_name_cold_waves]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing the predictions of the climatological ensemble and the RFC model for separate winters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# For illustration purposes, the fraction of ensemble members of the RFC predicting a cold waves\n",
    "# is plotted with the cold waves and the ground truth. This gives a first impression about the \n",
    "# models' forecast skill.\n",
    "for i in range(len(start_years_of_winter)):\n",
    "    fig,ax = plt.subplots()\n",
    "\n",
    "    cold_wave_days = np.array(cold_waves[i])\n",
    "    if calendar.isleap(start_years_of_winter[i]+1):\n",
    "        df_cold_wave_days = cold_wave_days[0:len(cold_wave_days)]\n",
    "    else: \n",
    "        df_cold_wave_days = cold_wave_days[0:len(cold_wave_days)-6]\n",
    "   \n",
    "    cold_wave_days = np.array(df_cold_wave_days)\n",
    "   \n",
    "    indices_cold_wave_days = np.where(np.squeeze(cold_wave_days)==1)  \n",
    "    indices_cold_wave_days = indices_cold_wave_days[0]\n",
    "    indices_cold_wave_days = indices_cold_wave_days[0:len(indices_cold_wave_days)-1] \n",
    "    for k in indices_cold_wave_days:\n",
    "        ax.axvspan(forecast_dates[i][k], forecast_dates[i][k+1], facecolor='grey', alpha=.2)\n",
    "\n",
    "    ax.plot(forecast_dates[i], climatological_ensemble_cold_waves[i], marker='x', markersize=3.5, linestyle='', color='r', alpha=0.5, label='Climatological Ensemble')    \n",
    "    ax.plot(forecast_dates[i], predictions_rfc[i], marker='o',markersize=3.5, linestyle='', color='b', alpha=0.5, label=config['rfc_model_name']+', '+str(config['lead_time'])+'d lead')    \n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylim(0, 0.6) \n",
    "   # plt.legend(bbox_to_anchor=(0, -0.45), loc='upper left') # standalone legend for the paper\n",
    "   # plt.ylabel(var_column_name_predictions_rfc) # shorten for paper\n",
    "    plt.ylabel('Fraction of \\n Ensemble Members')    \n",
    "    plt.savefig(config['PATH_plots']+config['rfc_model_name']+'_'+config['binary_ground_truth']+'_lead_'+str(config['lead_time'])+'d_'+str(start_years_of_winter[i])+'_'+str(start_years_of_winter[i]+1)+'.png', bbox_inches='tight')\n",
    "    #plt.show() # not used since the size of the jupyter notebook is really big\n",
    "    plt.close() # only used since the size of the jupyter notebook is really big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a standalone legend for the plot visualizing the climatological ensemble, the RFC\n",
    "# predictions and the ground truth.\n",
    "red_crosses = plt.Line2D([], [], marker='x', markersize=3.5, linestyle='', color='r', alpha=0.5, label='Climatological Ensemble')\n",
    "blue_dots = plt.Line2D([], [], marker='o',markersize=3.5, linestyle='', color='b', alpha=0.5, label=config['rfc_model_name']+', '+str(config['lead_time'])+'d lead')\n",
    "grey_filling = mpatches.Patch(color='grey', alpha=0.2, label='Ground Truth Cold Waves (E-OBS)')\n",
    "plt.legend(handles=[red_crosses, grey_filling, blue_dots], ncol=2)\n",
    "plt.axis(False)\n",
    "plt.savefig(config['PATH_plots']+'Standalone_legend_for_visualization_binary_predictions.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End of Program"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
