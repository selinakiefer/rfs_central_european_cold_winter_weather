{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting with Random Forest Classifier (RFC) Models\n",
    "\n",
    "Version 19 December 2022, Selina Kiefer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input: csv-file, pt-file\n",
    "continuous timeseries of input data (e.g. statistics of meteorological predictor fields), Random Forest Classifier models in pt-format\n",
    "### Output: csv-file, png-file\n",
    "predictions of the Random Forest Classifier models as timeseries of cold wave days in csv-format and plotted for one winter exemplarily in png-format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the paths' to the defined functions and configuration file and set its name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the defined functions.\n",
    "PATH_defined_functions = './Defined_Functions/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path and name of the configuration file.\n",
    "PATH_configurations = './Configuration_Files/'\n",
    "ifile_configurations = 'Configurations_RFC_Forecast.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the necessary python packages and functions\n",
    "Nothing needs to be changed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary python packages.\n",
    "import yaml\n",
    "import calendar\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from skranger.ensemble import RangerForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary python packages and functions.\n",
    "import sys\n",
    "sys.path.insert(1, PATH_defined_functions)\n",
    "from read_in_csv_data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the configuration file and the data specified in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the configuration file (nothing needs to be changed here).\n",
    "with open(PATH_configurations+ifile_configurations) as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the input data and remove any unnamed columns as well as the index column (nothing \n",
    "# needs to be changed here).\n",
    "df_input_data = read_in_csv_data(config['PATH_input_data'], config['ifile_input_data'])\n",
    "df_input_data = df_input_data.loc[:, ~df_input_data.columns.str.contains('^Unnamed')]\n",
    "df_input_data = df_input_data.drop(['index'], axis =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the name of the columns containing the time and the variables of the input data.\n",
    "time_column_name_input_data = df_input_data.columns[0]\n",
    "var_column_name_input_data = df_input_data.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that everything is selected correctly (nothing needs to be changed here).\n",
    "print('Predictors used for training the ML model: ')\n",
    "print(var_column_name_input_data)\n",
    "print('Name of the column containing the time: ')\n",
    "print(time_column_name_input_data)\n",
    "print('Dataframe containing the predictors: ')\n",
    "df_input_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing the input data for forecasting\n",
    "From here on, nothing needs to be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list with all the start years of the winters to be predicted is created. \n",
    "start_years_of_winter = np.arange(config['start_year_of_first_winter'], config['start_year_of_last_winter']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to extract the different winters to be predicted, the index of the dataframe\n",
    "# containing the input data is set to the time. The time column is converted beforehand into a\n",
    "# datetime-object.\n",
    "df_input_data[time_column_name_input_data] = pd.to_datetime(df_input_data[time_column_name_input_data])\n",
    "df_input_data = df_input_data.set_index(time_column_name_input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forecasting with the RFC-models\n",
    "For every winter to be predicted, the respective RFC model trained with the leave-one(-winter)-out cross-validation is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, the forecasting with the RFCs takes place. At first, the model used for forecasting the \n",
    "# respective winter is loaded. Then, the start- and end-date of this winter is determined and\n",
    "# the number of days which has to be taken from the month before the winter. This is done to\n",
    "# take the lead time into account and start the prediction with the first day of the winter.\n",
    "# In a next steps, the days of winter computed in order to create a list of forecast dates.\n",
    "# These are needed to assign the predictions of the RFCs to a date later. Then, the respective\n",
    "# winter is extracted from the input data (.loc[]) and the time column removed. Now, the loaded\n",
    "# RFC model is used to predict the occurrence of cold wave days. These predictions are saved to a list.\n",
    "# This is done for every winter in the evaluation period separately.\n",
    "predictions = []\n",
    "forecast_dates = []\n",
    "\n",
    "for i in range(len(start_years_of_winter)):\n",
    "    \n",
    "    random_forest_classifier = torch.load(config['PATH_model']+config['list_file_name_model'][i])\n",
    "    \n",
    "    start_winter = datetime(start_years_of_winter[i], config['start_month_winter'], config['start_day_winter'])\n",
    "    month_before_start_winter = datetime(start_years_of_winter[i], config['start_month_winter']-1, config['start_day_winter'])\n",
    "    end_winter = datetime(start_years_of_winter[i]+1, config['end_month_winter'], config['end_day_winter'])\n",
    "    \n",
    "    days_of_winter = ((end_winter-start_winter).days)+1\n",
    "    forecast_dates_winter = [start_winter + timedelta(days=x) for x in range(0, days_of_winter)]\n",
    "\n",
    "    df_X_val = df_input_data.loc[(df_input_data.index > month_before_start_winter) & (df_input_data.index < end_winter)]    \n",
    "    df_X_val = df_X_val.reset_index()\n",
    "        \n",
    "    X_val = df_X_val.drop([time_column_name_input_data], axis=1)\n",
    "    predictions_rfc = random_forest_classifier.predict_proba(X_val)\n",
    "    predictions.append(predictions_rfc[:,1])\n",
    "    forecast_dates.extend(forecast_dates_winter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bringing the forecasts into a nice representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a nice representation of the predictions in a pandas dataframe, list containing the\n",
    "# predictions is transposed, so that each predicted winter can be extracted easily. For every\n",
    "# day of the winter, the respective forecast is stored first as a numpy array and then \n",
    "# appended to a new dataframe which contains every prediction in a nicely sorted way.\n",
    "df_predictions = pd.DataFrame()\n",
    "\n",
    "days_of_regular_winter = days_of_winter\n",
    "\n",
    "if calendar.isleap(config['start_year_of_last_winter']+1)==False:\n",
    "    days_of_regular_winter = days_of_winter+1\n",
    "    \n",
    "for k in range(len(start_years_of_winter)):\n",
    "    predictions_single_winter = np.transpose(np.array(predictions[k]))\n",
    "    if calendar.isleap(start_years_of_winter[k]+1):\n",
    "        for l in range(days_of_regular_winter):\n",
    "            predictions_daily = np.array(predictions_single_winter[l])\n",
    "            df_predictions = df_predictions.append(pd.Series(predictions_daily), ignore_index=True)\n",
    "    else:\n",
    "        for m in range(days_of_regular_winter-1):\n",
    "            predictions_daily = np.array(predictions_single_winter[m])\n",
    "            df_predictions = df_predictions.append(pd.Series(predictions_daily), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To this dataframe, the forecast dates are added and moved to the beginning of the dataframe\n",
    "# for a good overview of the predictions.\n",
    "df_predictions = df_predictions.rename(columns={0:'Fraction of Ensembles Members \\n Predicting Cold Wave Day'})\n",
    "df_predictions['time'] = forecast_dates\n",
    "time_column = df_predictions.pop('time')\n",
    "df_predictions.insert(0, 'time', time_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the predictions in csv-format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, the dataframe is saved in csv-format.\n",
    "df_predictions.to_csv(config['PATH_predictions']+'RFC_predictions_'+config['ground_truth']+'_'+config['location_ground_truth']+'_input_'+config['input_data']+'_'+config['location_input']+'_lead_'+str(config['lead_time'])+'d_winter_'+str(config['start_year_of_first_winter'])+'_'+str(config['start_year_of_last_winter']+1)+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing the predictions of one winter for a plausibility check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For simplicity, the first predicted winter is plotted for a plausibility check.\n",
    "fig = plt.subplots()\n",
    "\n",
    "start_winter = datetime(start_years_of_winter[0], config['start_month_winter'], config['start_day_winter'])\n",
    "end_winter = datetime(start_years_of_winter[1], config['end_month_winter'], config['end_day_winter'])\n",
    "days_of_winter = ((end_winter-start_winter).days)+1\n",
    "\n",
    "plt.plot(df_predictions['time'].iloc[0:days_of_winter-1], df_predictions['Fraction of Ensembles Members \\n Predicting Cold Wave Day'].iloc[0:180], marker='o', linestyle='', color='k')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Fraction od ensemble members \\n predicting a cold wave days')\n",
    "plt.title('QRF Predictions for the Winter '+str(config['start_year_of_first_winter'])+'/'+str(config['start_year_of_first_winter']+1))\n",
    "plt.savefig(config['PATH_predictions']+'RFC_predictions_'+config['ground_truth']+'_'+config['location_ground_truth']+'_input_'+config['input_data']+'_'+config['location_input']+'_lead_'+str(config['lead_time'])+'d_winter_'+str(config['start_year_of_first_winter'])+'_'+str(config['start_year_of_first_winter']+1)+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End of Program"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
